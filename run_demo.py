# Relative Path: run_demo.py
#!/usr/bin/env python3
"""
è¿è¡Œæ¼”ç¤º
è¿è¡Œä¸€ä¸ªç®€çŸ­çš„æ¼”ç¤ºï¼Œå±•ç¤ºå·¥æ§è‡ªå­¦ä¹ ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½
"""

import yaml
import json
import os
from datetime import datetime
from typing import Dict, Any

from simulator.data_generator import TrafficGenerator
from simulator.packet_parser import PacketParser
from simulator.learner.comm_learner import CommunicationLearner
from simulator.learner.value_learner import ValueLearner
from simulator.model.models import PacketMetadata, ProtocolData, LearningContext
from simulator.model.database import ObservationDatabase

def load_config(config_path: str = "config.yaml") -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def run_demo():
    """è¿è¡Œæ¼”ç¤º"""
    print("ğŸ­ å·¥æ§è‡ªå­¦ä¹ ç³»ç»Ÿ - æ¼”ç¤ºç‰ˆ")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    config = load_config()
    print(f"âš™ï¸  ä½¿ç”¨é…ç½®: config.yaml")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("outputs", exist_ok=True)
    
    # åˆå§‹åŒ–å­¦ä¹ ä¸Šä¸‹æ–‡ï¼ˆ2å°æ—¶å­¦ä¹ ï¼‰
    context = LearningContext(
        mode='training',
        start_time=datetime.now(),
        duration_days=1,  # å®é™…ä¸Šæˆ‘ä»¬åªå­¦ä¹ 2å°æ—¶ï¼Œä½†è®¾ç½®ä¸º1å¤©
        min_observation_count=config.get('learning', {}).get('min_observation_count', 10),
        min_observation_days=config.get('learning', {}).get('min_observation_days', 2)
    )
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = ObservationDatabase()
    
    # åˆå§‹åŒ–å­¦ä¹ å™¨
    packet_parser = PacketParser(config)
    comm_learner = CommunicationLearner(config, context, db)
    value_learner = ValueLearner(config, context, packet_parser, db)
    
    # åˆå§‹åŒ–æµé‡ç”Ÿæˆå™¨
    generator = TrafficGenerator(config)
    
    print("ğŸš€ å¼€å§‹å­¦ä¹ é˜¶æ®µï¼ˆ2å°æ—¶æ¨¡æ‹Ÿï¼‰")
    print("-" * 40)
    
    # æ¨¡æ‹Ÿ2å°æ—¶çš„æµé‡ï¼ˆå®é™…è¿è¡Œæ—¶é—´ä¼šæ›´å¿«ï¼‰
    total_minutes = 120
    batch_minutes = 10  # æ¯æ¬¡å¤„ç†10åˆ†é’Ÿçš„æµé‡
    
    processed_minutes = 0
    while processed_minutes < total_minutes:
        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„æ—¶é•¿
        current_batch = min(batch_minutes, total_minutes - processed_minutes)
        
        # ç”Ÿæˆä¸€æ‰¹æµé‡
        packets = generator.generate_traffic_batch(current_batch)
        
        # å¤„ç†æ¯ä¸ªæ•°æ®åŒ…
        for packet_meta, proto_data in packets:
            # é€šä¿¡å­¦ä¹ å™¨å­¦ä¹ 
            comm_learner.learn(packet_meta, proto_data)
            
            # å€¼åŸŸå­¦ä¹ å™¨å­¦ä¹ 
            value_learner.learn(packet_meta, proto_data)
        
        # æ›´æ–°ä¸Šä¸‹æ–‡
        context.total_packets_processed += len(packets)
        context.total_sessions_observed += len([p for p in packets if p[1] is not None])
        
        # æ›´æ–°è¿›åº¦
        processed_minutes += current_batch
        progress = processed_minutes / total_minutes * 100
        print(f"ğŸ“Š è¿›åº¦: {progress:.1f}% ({processed_minutes}/{total_minutes}) "
              f"- å·²å¤„ç† {context.total_packets_processed} ä¸ªæ•°æ®åŒ…")
    
    print("\nâœ… å­¦ä¹ é˜¶æ®µå®Œæˆ")
    
    # å®Œæˆå­¦ä¹ 
    comm_result = comm_learner.finalize_learning()
    value_result = value_learner.finalize_learning()
    
    print(f"ğŸ“ˆ é€šä¿¡å­¦ä¹ ç»“æœ: {comm_result['total_connections']} ä¸ªè¿æ¥, "
          f"{comm_result['approved_connections']} ä¸ªæ‰¹å‡†")
    print(f"ğŸ“ˆ å€¼åŸŸå­¦ä¹ ç»“æœ: {value_result['total_parameters']} ä¸ªå‚æ•°, "
          f"{value_result['valid_models']} ä¸ªæœ‰æ•ˆæ¨¡å‹")
    
    # ç”Ÿæˆç™½åå•
    print("\nğŸ“‹ ç”Ÿæˆç™½åå•...")
    whitelist = {
        'generated_at': datetime.now().isoformat(),
        'learning_duration_hours': 2,
        'communication_rules': [],
        'value_rules': []
    }
    
    # æ·»åŠ æ‰¹å‡†çš„è¿æ¥åˆ°ç™½åå•
    approved_connections = comm_learner.get_approved_connections()
    for conn in approved_connections:
        whitelist['communication_rules'].append({
            'src_ip': conn.src_ip,
            'dst_ip': conn.dst_ip,
            'dst_port': conn.dst_port,
            'protocol': conn.protocol,
            'confidence': conn.confidence,
            'observation_count': conn.observation_count
        })
    
    # æ·»åŠ å€¼åŸŸè§„åˆ™
    for (protocol, address), value_obs in value_learner.value_observations.items():
        if value_obs.observation_count >= value_learner.min_value_observations and value_obs.baseline_min is not None:
            whitelist['value_rules'].append({
                'address': value_obs.address,
                'min_value': value_obs.baseline_min,
                'max_value': value_obs.baseline_max,
                'mean': value_obs.mean,
                'std_dev': value_obs.std_dev,
                'observations': value_obs.observation_count
            })
    
    # ä¿å­˜ç™½åå•
    whitelist_path = "outputs/demo_whitelist.json"
    with open(whitelist_path, 'w', encoding='utf-8') as f:
        json.dump(whitelist, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ ç™½åå•å·²ä¿å­˜åˆ° {whitelist_path}")
    print(f"   - {len(whitelist['communication_rules'])} ä¸ªé€šä¿¡è§„åˆ™")
    print(f"   - {len(whitelist['value_rules'])} ä¸ªå€¼åŸŸè§„åˆ™")
    
    # ç®€å•éªŒè¯æµ‹è¯•
    print("\nğŸ” è¿è¡ŒéªŒè¯æµ‹è¯•...")
    
    # ç”Ÿæˆä¸€äº›æ­£å¸¸æµé‡è¿›è¡Œæµ‹è¯•
    test_packets = generator.generate_traffic_batch(5)  # 5åˆ†é’Ÿæµ‹è¯•æµé‡
    
    valid_count = 0
    invalid_count = 0
    
    for packet_meta, proto_data in test_packets:
        # æµ‹è¯•é€šä¿¡éªŒè¯
        comm_result = comm_learner.validate(packet_meta, proto_data)
        value_result = value_learner.validate(packet_meta, proto_data)
        
        if comm_result['approved'] and value_result['approved']:
            valid_count += 1
        else:
            invalid_count += 1
    
    print(f"âœ… éªŒè¯ç»“æœ: {valid_count} ä¸ªæœ‰æ•ˆ, {invalid_count} ä¸ªæ— æ•ˆ")
    
    # ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š
    report = {
        'demo_time': datetime.now().isoformat(),
        'total_packets_processed': context.total_packets_processed,
        'total_connections_observed': context.total_sessions_observed,
        'approved_connections': len(whitelist['communication_rules']),
        'value_rules': len(whitelist['value_rules']),
        'validation_results': {
            'test_packets': len(test_packets),
            'valid_packets': valid_count,
            'invalid_packets': invalid_count
        }
    }
    
    report_path = "outputs/demo_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“Š å­¦ä¹ æŠ¥å‘Šå·²ä¿å­˜åˆ° {report_path}")
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)

if __name__ == "__main__":
    run_demo()